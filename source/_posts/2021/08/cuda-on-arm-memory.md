---
title: CUDA on Arm - å­˜å‚¨å•å…ƒ
category_bar: true
date: 2021-08-24 15:42:20
tags: ['jetson','cuda','ubuntu', 'GPU', 'ARM']
categories:
- æŠ€æœ¯
- Course
- CUDA
---

ğŸ‰æ„Ÿè°¢æ¥è‡ªNVIDIAä¼ä¸šçº§å¼€å‘è€…ç¤¾åŒºçš„ä½•ç¨ï¼ˆKenï¼‰è€å¸ˆæä¾›çš„èµ„æ–™å’Œç»†è‡´è€å¿ƒçš„è®²è§£

æœ¬ç¯‡ä¸æ¶‰åŠå­˜å‚¨å•å…ƒçš„åŠ é€Ÿä¼˜åŒ–ï¼Œé‡ç‚¹æ¼”ç¤ºæœ€åŸºç¡€çš„å†…å­˜ç”³è¯·é‡Šæ”¾ã€æ•°æ®æ‹·è´ä¼ è¾“

## å­˜å‚¨å•å…ƒ

ï¼ˆè¿™å—å¹¶æ²¡æœ‰å®Œå…¨å­¦å®Œï¼ŒConstant memoryå’ŒTexture memoryå­˜å‚¨ä»‹ç»å†…å®¹æ¥æºäºæœç´¢å¼•æ“ï¼‰

![image-20210823233746897](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/23/image-20210823233746897.png)

### Register

å¯„å­˜å™¨æ˜¯GPUæœ€å¿«çš„memoryï¼Œå¯„å­˜å™¨å˜é‡æ˜¯æ¯ä¸ªçº¿ç¨‹ç§æœ‰çš„ï¼Œä¸€æ—¦threadæ‰§è¡Œç»“æŸï¼Œå¯„å­˜å™¨å˜é‡å°±ä¼šå¤±æ•ˆã€‚å¯„å­˜å™¨æ˜¯ç¨€æœ‰èµ„æºã€‚åœ¨Fermiä¸Šï¼Œæ¯ä¸ªthreadé™åˆ¶æœ€å¤šæ‹¥æœ‰63ä¸ªregisterï¼ŒKepleråˆ™æ˜¯255ä¸ªã€‚è®©è‡ªå·±çš„kernelä½¿ç”¨è¾ƒå°‘çš„registerå°±èƒ½å¤Ÿå…è®¸æ›´å¤šçš„blocké©»ç•™åœ¨SMä¸­ï¼Œä¹Ÿå°±å¢åŠ äº†Occupancyï¼Œæå‡äº†æ€§èƒ½ã€‚

å¯„å­˜å™¨ä¸åƒå…±äº«å†…å­˜ã€è®¾å¤‡å†…å­˜ã€å¸¸é‡å†…å­˜å’Œçº¹ç†å†…å­˜æ˜¾å¼å£°æ˜ï¼Œå®ƒä»¬çš„å£°æ˜ä¸åŠ ä»»ä½•é™å®šç¬¦ï¼Œå°±å¦‚æ™®é€šå˜é‡ä¸€æ ·ï¼Œå¦‚` int a`ã€‚

å¯„å­˜å™¨ä¸»è¦æ‰¿æ‹…Scalar variablesï¼ˆæ ‡é‡å˜é‡ï¼‰å’Œç¼–è¯‘æ—¶å·²çŸ¥çš„é™æ€ç´¢å¼•çš„æ•°ç»„ã€‚

### Local memory

æœ‰æ—¶å€™ï¼Œå¦‚æœRegisterä¸å¤Ÿç”¨äº†ï¼Œé‚£ä¹ˆå°±ä¼šä½¿ç”¨Local memoryæ¥ä»£æ›¿è¿™éƒ¨åˆ†å¯„å­˜å™¨ç©ºé—´ã€‚

é™¤æ­¤å¤–ï¼Œä¸‹é¢å‡ ç§æƒ…å†µï¼Œç¼–è¯‘å™¨å¯èƒ½ä¼šæŠŠå˜é‡æ”¾ç½®åœ¨Local memoryï¼š

- ç¼–è¯‘æœŸæ— æ³•å†³å®šç¡®åˆ‡å€¼çš„æœ¬åœ°æ•°ç»„ã€‚
- è¾ƒå¤§çš„ç»“æ„ä½“æˆ–è€…æ•°ç»„ï¼Œä¹Ÿå°±æ˜¯é‚£äº›å¯èƒ½ä¼šæ¶ˆè€—å¤§é‡Registerçš„å˜é‡ã€‚
- ä»»ä½•è¶…è¿‡å¯„å­˜å™¨é™åˆ¶çš„å˜é‡ã€‚

åœ¨Local memoryä¸­çš„å˜é‡æœ¬è´¨ä¸Šè·ŸGlobal memoryåœ¨åŒä¸€å—å­˜å‚¨åŒºã€‚æ‰€ä»¥ï¼ŒLocal memoryæœ‰å¾ˆé«˜çš„atencyå’Œè¾ƒä½çš„bandwidthã€‚åœ¨CC2.0ä»¥ä¸Šï¼ŒGPUé’ˆå¯¹Local memoryä¼šæœ‰L1ï¼ˆper-SMï¼‰å’ŒL2ï¼ˆper-deviceï¼‰ä¸¤çº§cacheã€‚

### Shared memory

ç”¨\_\_shared\_\_ä¿®é¥°ç¬¦ä¿®é¥°çš„å˜é‡å­˜æ”¾åœ¨Shared memoryã€‚å› ä¸ºShared memoryæ˜¯on-chipçš„ï¼Œä»–ç›¸æ¯”Local Memoryå’ŒGlobal memoryæ¥è¯´ï¼Œæ‹¥æœ‰é«˜çš„å¤šbandwidthå’Œä½å¾ˆå¤šçš„latencyã€‚ä»–çš„ä½¿ç”¨å’ŒCPUçš„L1 cacheéå¸¸ç±»ä¼¼ï¼Œä½†æ˜¯ä»–æ˜¯programmableçš„ã€‚

æŒ‰æƒ¯ä¾‹ï¼Œåƒè¿™ç±»æ€§èƒ½è¿™ä¹ˆå¥½çš„memoryéƒ½æ˜¯æœ‰é™åˆ¶çš„ï¼ŒShared memoryæ˜¯ä»¥blockä¸ºå•ä½åˆ†é…çš„ã€‚æˆ‘ä»¬å¿…é¡»éå¸¸å°å¿ƒçš„ä½¿ç”¨Shared memoryï¼Œå¦åˆ™ä¼šæ— æ„è¯†çš„é™åˆ¶äº†active warpçš„æ•°ç›®ã€‚

ä¸åŒäºRegisterï¼ŒShared memoryå°½ç®¡åœ¨kernelé‡Œå£°æ˜çš„ï¼Œä½†æ˜¯ä»–çš„ç”Ÿå‘½å‘¨æœŸæ˜¯ä¼´éšæ•´ä¸ªblockï¼Œè€Œä¸æ˜¯å•ä¸ªthreadã€‚å½“è¯¥blockæ‰§è¡Œå®Œæ¯•ï¼Œä»–æ‰€æ‹¥æœ‰çš„èµ„æºå°±ä¼šè¢«é‡Šæ”¾ï¼Œé‡æ–°åˆ†é…ç»™åˆ«çš„blockã€‚

Shared memoryæ˜¯threadäº¤æµçš„åŸºæœ¬æ–¹å¼ã€‚åŒä¸€ä¸ªblockä¸­çš„threadé€šè¿‡Shared memoryä¸­çš„æ•°æ®æ¥ç›¸äº’åˆä½œã€‚è·å–Shared memoryçš„æ•°æ®å‰å¿…é¡»å…ˆç”¨__syncthreads()åŒæ­¥ã€‚

### Global memory

Global Memoryæ˜¯ç©ºé—´æœ€å¤§ï¼Œlatencyæœ€é«˜ï¼ŒGPUæœ€åŸºç¡€çš„memoryã€‚â€œglobalâ€æŒ‡æ˜äº†å…¶ç”Ÿå‘½å‘¨æœŸã€‚ä»»æ„SMéƒ½å¯ä»¥åœ¨æ•´ä¸ªç¨‹åºçš„ç”Ÿå‘½æœŸä¸­è·å–å…¶çŠ¶æ€ã€‚globalä¸­çš„å˜é‡æ—¢å¯ä»¥æ˜¯é™æ€ä¹Ÿå¯ä»¥æ˜¯åŠ¨æ€å£°æ˜ã€‚å¯ä»¥ä½¿ç”¨\_\_device\_\_ä¿®é¥°ç¬¦æ¥é™å®šå…¶å±æ€§ã€‚Global memoryçš„åˆ†é…å°±æ˜¯ä¹‹å‰é¢‘ç¹ä½¿ç”¨çš„`cudaMalloc`ï¼Œé‡Šæ”¾ä½¿ç”¨`cudaFree`ã€‚Global memoryé©»ç•™åœ¨Device memoryï¼Œå¯ä»¥é€šè¿‡32-byteã€64-byteæˆ–è€…128-byteä¸‰ç§æ ¼å¼ä¼ è¾“ã€‚è¿™äº›memory transactionå¿…é¡»æ˜¯å¯¹é½çš„ï¼Œä¹Ÿå°±æ˜¯è¯´é¦–åœ°å€å¿…é¡»æ˜¯32ã€64æˆ–è€…128çš„å€æ•°ã€‚ä¼˜åŒ–memory transactionå¯¹äºæ€§èƒ½æå‡è‡³å…³é‡è¦ã€‚å½“warpæ‰§è¡Œmemory load/storeæ—¶ï¼Œéœ€è¦çš„transactionæ•°é‡ä¾èµ–äºä¸‹é¢ä¸¤ä¸ªå› ç´ ï¼š

1. Distribution of memory address across the thread of that warp å°±æ˜¯å‰æ–‡çš„è¿ç»­
2. Alignment of memory address per transaction å¯¹é½

ä¸€èˆ¬æ¥è¯´ï¼Œæ‰€éœ€æ±‚çš„transactionè¶Šå¤šï¼Œæ½œåœ¨çš„ä¸å¿…è¦æ•°æ®ä¼ è¾“å°±è¶Šå¤šï¼Œä»è€Œå¯¼è‡´throughput efficiencyé™ä½ã€‚

### Constant memory

Constant Memoryé©»ç•™åœ¨Device Memoryï¼Œå¹¶ä¸”ä½¿ç”¨ä¸“ç”¨çš„Constant cacheï¼ˆper-SMï¼‰ã€‚è¯¥Memoryçš„å£°æ˜åº”è¯¥ä»¥\_\_connstant\_\_ä¿®é¥°ã€‚Constantçš„èŒƒå›´æ˜¯å…¨å±€çš„ï¼Œé’ˆå¯¹æ‰€æœ‰kernelï¼Œå¯¹äºæ‰€æœ‰CCå…¶å¤§å°éƒ½æ˜¯64KBã€‚åœ¨åŒä¸€ä¸ªç¼–è¯‘å•å…ƒï¼ŒConstantå¯¹æ‰€æœ‰kernelå¯è§ã€‚

å½“ä¸€ä¸ªwarpä¸­æ‰€æœ‰threadéƒ½ä»åŒä¸€ä¸ªMemoryåœ°å€è¯»å–æ•°æ®æ—¶ï¼ŒConstant Memoryè¡¨ç°æœ€å¥½ã€‚ä¾‹å¦‚ï¼Œè®¡ç®—å…¬å¼ä¸­çš„ç³»æ•°ã€‚å¦‚æœæ‰€æœ‰çš„threadä»ä¸åŒçš„åœ°å€è¯»å–æ•°æ®ï¼Œå¹¶ä¸”åªè¯»ä¸€æ¬¡ï¼Œé‚£ä¹ˆConstant memoryå°±ä¸æ˜¯å¾ˆå¥½çš„é€‰æ‹©ï¼Œå› ä¸ºä¸€æ¬¡è¯»Constant memoryæ“ä½œä¼šå¹¿æ’­ç»™æ‰€æœ‰threadçŸ¥é“ã€‚

### Texture memory

Texture Memoryé©»ç•™åœ¨Device memoryä¸­ï¼Œå¹¶ä¸”ä½¿ç”¨ä¸€ä¸ªåªè¯»cacheï¼ˆper-SMï¼‰ã€‚Texture Memoryå®é™…ä¸Šä¹Ÿæ˜¯Global Memoryåœ¨ä¸€å—ï¼Œä½†æ˜¯ä»–æœ‰è‡ªå·±ä¸“æœ‰çš„åªè¯»cacheã€‚è¿™ä¸ªcacheåœ¨æµ®ç‚¹è¿ç®—å¾ˆæœ‰ç”¨ã€‚Texture Memoryæ˜¯é’ˆå¯¹2Dç©ºé—´å±€éƒ¨æ€§çš„ä¼˜åŒ–ç­–ç•¥ï¼Œæ‰€ä»¥threadè¦è·å–2Dæ•°æ®å°±å¯ä»¥ä½¿ç”¨Texture Memoryæ¥è¾¾åˆ°å¾ˆé«˜çš„æ€§èƒ½ã€‚

## å†…å­˜çš„åˆ†é…ä¸å›æ”¶

CPUå†…å­˜

- malloc()
- memset()
- free()

GPUå†…å­˜

- cudaMalloc()
- cudaMemset()
- cudaFree()

**å½“æˆ‘ä»¬è¦ä¸ºä¸€ä¸ªæ–¹é˜µ`M[m * m]`ç”³è¯·GPUçš„å­˜å‚¨å•å…ƒæ—¶**

```c
cudaMalloc((void **) &d_m,sizeof(int) * m * m);
```

**d_mï¼š**æŒ‡å‘å­˜å‚¨åœ¨Deviceç«¯æ•°æ®çš„åœ°å€çš„æŒ‡é’ˆï¼ˆåŒé‡æŒ‡é’ˆï¼‰ã€‚

**sizeof(int) \* m \* mï¼š**å­˜å‚¨åœ¨Deviceç«¯ç©ºé—´çš„å¤§å°ã€‚

**å½“æˆ‘ä»¬è¦é‡Šæ”¾ç”³è¯·çš„GPUçš„å­˜å‚¨å•å…ƒæ—¶**

```c
cudaFree(d_m);
```

d_mï¼šæŒ‡å‘å­˜å‚¨åœ¨Deviceç«¯æ•°æ®çš„åœ°å€çš„æŒ‡é’ˆã€‚

## å†…å­˜æ‹·è´

**cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind)**

- **dst:** ç›®çš„å†…å­˜åœ°å€
- **src:** æºå†…å­˜åœ°å€
- **count:** ä»¥å­—èŠ‚ä¸ºå•ä½è¦æ‹·è´çš„æ•°æ®å¤§å°
- **kind:** æ•°æ®ä¼ è¾“æ–¹å‘

**cudaMemcpyKind**

- cudaMemcpyHostToDevice
- cudaMemcpyDeviceToHost
- cudaMemcpyDeviceToDevice
- cudaMemcpyHostToHost

**å½“æˆ‘ä»¬è¦å°†å‡†å¤‡å¥½çš„æ•°æ®ä»CPUå†…å­˜ä¼ è¾“åˆ°GPUçš„å­˜å‚¨å•å…ƒæ—¶**

```c
cudaMemcpy(d_m, h_m, sizeof(int) * m * m, cudaMemcpyHostToDevice);
```

**d_mï¼š**ä¼ è¾“çš„ç›®çš„åœ°ï¼ŒGPUå­˜å‚¨å•å…ƒ

**h_mï¼š**æ•°æ®çš„æºåœ°å€ï¼ŒCPUå­˜å‚¨å•å…ƒ

**sizeof(int) \* m \* mï¼š**æ•°æ®ä¼ è¾“çš„å¤§å°

**cudaMemcpyHostToDeviceï¼š**æ•°æ®ä¼ è¾“çš„æ–¹å‘ï¼ŒCPU -> GPU

**å½“æˆ‘ä»¬è¦å°†å‡†å¤‡å¥½çš„æ•°æ®ä»GPUå­˜å‚¨å•å…ƒä¼ è¾“åˆ°CPUçš„å†…å­˜æ—¶**

```c
cudaMemcpy(h_c, d_c, sizeof(int) * m * k, cudaMemcpyDeviceToHost);
```

## å®éªŒï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰

![image-20210824000328785](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/24/image-20210824000328785.png)

çŸ©é˜µç›¸ä¹˜è®¡ç®—æ ·ä¾‹ï¼š

![image-20210823235724074](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/23/image-20210823235724074.png)

### CPUçŸ©é˜µä¹˜æ³•

ä½¿ç”¨CPUå®Œæˆè¿™ä¸€è¿‡ç¨‹ï¼š

```c
void cpu_matrix_mult(int *h_m, int *h_n, int *h_result, int m, int n, int k){
	for (int i = 0; i < m; ++i){
		for (int j = 0; j < k; ++j){
			int tmp = 0.0;
			for (int h = 0; h < n; ++h){
				tmp += h_m[i * n + h] * h_n[h * k + j];
            }
			h_result[i * k + j] = tmp;
        }
	}
}


```

å¯è§æ•´ä¸ªè®¡ç®—è¿‡ç¨‹éœ€è¦å®Œæˆä¸‰é‡å¾ªç¯ï¼Œæ€»å…±éœ€è¦è®¡ç®—`m * n * k`æ¬¡`tmp += h_m[i * n + h] * h_n[h * k + j];`æ‰èƒ½å®Œæˆè®¡ç®—ã€‚ä¸‹é¢é‡‡ç”¨CUDAçš„å¹¶è¡Œç¼–ç¨‹æ¨¡å‹æ¥å°è¯•å»æ‰éƒ¨åˆ†å¾ªç¯è¿›è¡ŒåŠ é€Ÿã€‚

### äºŒç»´ç½‘æ ¼å’Œçº¿ç¨‹å—

ä¸ºäº†è§£å†³çŸ©é˜µä¹˜æ³•çš„é—®é¢˜ï¼Œéœ€è¦å…ˆæå®šäºŒç»´çŠ¶æ€ä¸‹çº¿ç¨‹çš„ç´¢å¼•è®¡ç®—ï¼ˆå½“ç„¶ä¹Ÿå¯ä»¥è½¬æ¢ä¸ºä¸€ç»´ï¼‰ã€‚

çº¿ç¨‹çš„ç´¢å¼•æ’åºæ–¹å¼å¦‚ä¸‹å›¾ï¼š

![image-20210824000858814](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/24/image-20210824000858814.png)

Global linear memory index: `idx = iy * nx + ix`

**ä»¥44å·çº¿ç¨‹ä¸ºä¾‹**

```c
int index = (blockIdx.y * blockDim.y + threadIdx.y) * nx+ (blockIdx.x * blockDim.x + threadIdx.x);
```

```c
Index = (2 * 2 + 1) * 8 + (1 * 4 + 0) 
Index = 44
```

![image-20210824001345666](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/24/image-20210824001345666.png)

å°†æ•´ä¸ªgridå¯¹åº”åˆ°æ•´ä¸ªçŸ©é˜µåï¼Œå°±å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![image-20210824001447544](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/24/image-20210824001447544.png)

### GPUçŸ©é˜µä¹˜æ³•

**gridä¸­å¤šçº¿ç¨‹è®¡ç®—Pd**

- æ¯ä¸ªçº¿ç¨‹è®¡ç®—Pdçš„ä¸€ä¸ªå…ƒç´ 

**æ¯ä¸ªçº¿ç¨‹**

- è¯»å…¥çŸ©é˜µMdçš„ä¸€è¡Œï¼Œè¯»å…¥çŸ©é˜µNdçš„ä¸€åˆ—
- ä¸ºæ¯å¯¹Mdå’ŒNdå…ƒç´ æ‰§è¡Œä¸€æ¬¡ä¹˜æ³•å’ŒåŠ æ³•

![image-20210824002247739](https://wpcos-1300629776.cos.ap-chengdu.myqcloud.com/Gallery/2021/08/24/image-20210824002247739.png)

### å®Œæ•´ä»£ç 

```c
#include <stdio.h>
#include <math.h>

#define BLOCK_SIZE 16

__global__ void gpu_matrix_mult(int *a,int *b, int *c, int m, int n, int k)
{ 
    int row = blockIdx.y * blockDim.y + threadIdx.y; 
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int sum = 0;
    if( col < k && row < m) 
    {
        for(int i = 0; i < n; i++) 
        {
            sum += a[row * n + i] * b[i * k + col];
        }
        c[row * k + col] = sum;
    }
} 

void cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {
    for (int i = 0; i < m; ++i) 
    {
        for (int j = 0; j < k; ++j) 
        {
            int tmp = 0.0;
            for (int h = 0; h < n; ++h) 
            {
                tmp += h_a[i * n + h] * h_b[h * k + j];
            }
            h_result[i * k + j] = tmp;
        }
    }
}

int main(int argc, char const *argv[])
{
    int m=1000;
    int n=2000;
    int k=3000;

    int *h_a, *h_b, *h_c, *h_cc;
    cudaMallocHost((void **) &h_a, sizeof(int)*m*n);
    cudaMallocHost((void **) &h_b, sizeof(int)*n*k);
    cudaMallocHost((void **) &h_c, sizeof(int)*m*k);
    cudaMallocHost((void **) &h_cc, sizeof(int)*m*k);

    for (int i = 0; i < m; ++i) {
        for (int j = 0; j < n; ++j) {
            h_a[i * n + j] = rand() % 1024;
        }
    }

    for (int i = 0; i < n; ++i) {
        for (int j = 0; j < k; ++j) {
            h_b[i * k + j] = rand() % 1024;
        }
    }

    int *d_a, *d_b, *d_c;
    cudaMalloc((void **) &d_a, sizeof(int)*m*n);
    cudaMalloc((void **) &d_b, sizeof(int)*n*k);
    cudaMalloc((void **) &d_c, sizeof(int)*m*k);

    // copy matrix A and B from host to device memory
    cudaMemcpy(d_a, h_a, sizeof(int)*m*n, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, sizeof(int)*n*k, cudaMemcpyHostToDevice);

    unsigned int grid_rows = (m + BLOCK_SIZE - 1) / BLOCK_SIZE;
    unsigned int grid_cols = (k + BLOCK_SIZE - 1) / BLOCK_SIZE;
    dim3 dimGrid(grid_cols, grid_rows);
    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);
    gpu_matrix_mult<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, m, n, k);    
    cudaMemcpy(h_c, d_c, sizeof(int)*m*k, cudaMemcpyDeviceToHost);

    cpu_matrix_mult(h_a, h_b, h_cc, m, n, k);

    int ok = 1;
    for (int i = 0; i < m; ++i)
    {
        for (int j = 0; j < k; ++j)
        {
            if(fabs(h_cc[i*k + j] - h_c[i*k + j])>(1.0e-10))
            {
                ok = 0;
            }
        }
    }

    if(ok)
    {
        printf("Pass!!!\n");
    }
    else
    {
        printf("Error!!!\n");
    }

    // free memory
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
    cudaFreeHost(h_a);
    cudaFreeHost(h_b);
    cudaFreeHost(h_c);
    return 0;
}
```

### ä»£ç è§£æ

#### æ ¸å‡½æ•°

```c
__global__ void gpu_matrix_mult(int *a,int *b, int *c, int m, int n, int k)
{ 
    int row = blockIdx.y * blockDim.y + threadIdx.y; 
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int sum = 0;
    if( col < k && row < m) 
    {
        for(int i = 0; i < n; i++) 
        {
            sum += a[row * n + i] * b[i * k + col];
        }
        c[row * k + col] = sum;
    }
} 
```

å…ˆè®¡ç®—å¥½å…ƒç´ åœ¨çŸ©é˜µä¸­çš„è¡Œå’Œåˆ—ï¼Œæ¯ä¸€ä¸ªçº¿ç¨‹å¤„ç†äº†çŸ©é˜µMdçš„ä¸€è¡Œå’ŒçŸ©é˜µNdçš„ä¸€åˆ—ï¼Œåˆ†åˆ«ç›¸ä¹˜å†ç›¸åŠ ã€‚å°†è®¡ç®—å¥½çš„æœ€ç»ˆå€¼å†™å…¥PdçŸ©é˜µçš„å¯¹åº”ä½ç½®å³å¯ã€‚

è¿™é‡Œéœ€è¦æ³¨æ„ç´¢å¼•çš„è®¡ç®—æ–¹å¼ï¼Œæˆ‘ä»¬è¾“å…¥çš„çŸ©é˜µå®é™…ä¸Šæ˜¯ä¸€ä¸ªä¸€ç»´çš„æ•°ç»„ï¼Œé‚£ä¹ˆéœ€è¦å°†äºŒç»´åæ ‡çº¿æ€§åŒ–ã€‚

#### CPUè®¡ç®—å‡½æ•°

```c
void cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {
    for (int i = 0; i < m; ++i) 
    {
        for (int j = 0; j < k; ++j) 
        {
            int tmp = 0.0;
            for (int h = 0; h < n; ++h) 
            {
                tmp += h_a[i * n + h] * h_b[h * k + j];
            }
            h_result[i * k + j] = tmp;
        }
    }
}
```

å°†CPUè®¡ç®—ç»“æœä½œä¸ºæ ‡å‡†æ¥å¯¹GPUè®¡ç®—ç»“æœè¿›è¡Œæ ¡éªŒã€‚

#### ä¸»å‡½æ•°

```c
int *h_a, *h_b, *h_c, *h_cc;
cudaMallocHost((void **) &h_a, sizeof(int)*m*n);
cudaMallocHost((void **) &h_b, sizeof(int)*n*k);
cudaMallocHost((void **) &h_c, sizeof(int)*m*k);
cudaMallocHost((void **) &h_cc, sizeof(int)*m*k);
```

å®šä¹‰å˜é‡å¹¶åœ¨Hostä¸Šåˆ†é…æ•°ç»„ç©ºé—´ã€‚

```c
for (int i = 0; i < m; ++i) {
    for (int j = 0; j < n; ++j) {
        h_a[i * n + j] = rand() % 1024;
    }
}

for (int i = 0; i < n; ++i) {
    for (int j = 0; j < k; ++j) {
        h_b[i * k + j] = rand() % 1024;
    }
}
```

åœ¨Hostç«¯åˆå§‹åŒ–æ•°ç»„ã€‚

```c
int *d_a, *d_b, *d_c;
cudaMalloc((void **) &d_a, sizeof(int)*m*n);
cudaMalloc((void **) &d_b, sizeof(int)*n*k);
cudaMalloc((void **) &d_c, sizeof(int)*m*k);
```

å®šä¹‰å˜é‡ï¼Œå¹¶è°ƒç”¨`cudaMalloc`åœ¨GPUç«¯ä¸ºå˜é‡åˆ†é…å†…å­˜ç©ºé—´ã€‚

```c
cudaMemcpy(d_a, h_a, sizeof(int)*m*n, cudaMemcpyHostToDevice);
cudaMemcpy(d_b, h_b, sizeof(int)*n*k, cudaMemcpyHostToDevice);
```

å°†åœ¨CPUç«¯åˆå§‹åŒ–å¥½çš„æ•°ç»„æ‹·è´åˆ°GPUï¼Œä¾¿äºåœ¨GPUå¹¶è¡Œå¤„ç†æ•°æ®ã€‚

```c
dim3 dimGrid(grid_cols, grid_rows);
dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);
gpu_matrix_mult<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, m, n, k); 
cudaMemcpy(h_c, d_c, sizeof(int)*m*k, cudaMemcpyDeviceToHost);
```

å®Œæˆæ‰§è¡Œè®¾ç½®å¹¶è°ƒç”¨æ ¸å‡½æ•°ï¼Œåœ¨GPUä¸Šå¼€å§‹ç¨‹åºçš„å¹¶è¡Œéƒ¨åˆ†ã€‚

è®¡ç®—å®Œæˆåç»“æœå­˜å‚¨åœ¨`d_c`æ‰€æŒ‡å‘çš„GPUå†…å­˜ä¸­ï¼Œéœ€è¦è°ƒç”¨`cudaMemcpy`å°†æ•°æ®ä»Deviceæ‹·è´åˆ°Hostä¸­ã€‚

```c
cpu_matrix_mult(h_a, h_b, h_cc, m, n, k);

int ok = 1;
for (int i = 0; i < m; ++i)
{
    for (int j = 0; j < k; ++j)
    {
        if(fabs(h_cc[i*k + j] - h_c[i*k + j])>(1.0e-10))
        {
            ok = 0;
        }
    }
}

if(ok)
{
    printf("Pass!!!\n");
}
else
{
    printf("Error!!!\n");
}
```

åœ¨CPUä¸­å®Œæˆæ ‡å‡†ç­”æ¡ˆçš„è®¡ç®—å¹¶ä¸GPUè®¡ç®—ç»“æœè¿›è¡Œå¯¹æ¯”æ ¡éªŒã€‚

```c
cudaFree(d_a);
cudaFree(d_b);
cudaFree(d_c);
cudaFreeHost(h_a);
cudaFreeHost(h_b);
cudaFreeHost(h_c);
```

è°ƒç”¨`cudaFree`ç›¸å…³å‡½æ•°é‡Šæ”¾åˆšåˆšåœ¨Hostå’ŒDeviceä¸­åˆ†é…çš„å†…å­˜ï¼Œéšå³ç¨‹åºç»“æŸã€‚